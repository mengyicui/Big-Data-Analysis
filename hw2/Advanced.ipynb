{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import *\n",
    "spark = SparkSession.builder.appName('Graphs-HW2').config(\"spark.sql.crossJoin.enabled\", True).getOrCreate()\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "pr_sdf = spark.read.load('pr_graph.txt', format=\"text\")\n",
    "pr_sdf = pr_sdf.select(F.split(pr_sdf.value, ' ')[0].alias('from_node').cast('int'),\n",
    "                            F.split(pr_sdf.value, ' ')[1].alias('to_node').cast('int'),\n",
    "                            F.split(pr_sdf.value, ' ')[2].alias('timestamp').cast('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pagerank(G, num_iter):\n",
    "    G.createOrReplaceTempView('G')\n",
    "    h1 = spark.sql('''SELECT DISTINCT from_node, ROW_NUMBER() OVER(ORDER BY from_node) AS count\n",
    "                FROM G\n",
    "                GROUP BY from_node''')\n",
    "\n",
    "    h1.createOrReplaceTempView('h1')\n",
    "    m = spark.sql('''SELECT MAX(count) AS max\n",
    "                FROM h1''')\n",
    "\n",
    "    N = 1/m.head()[0]\n",
    "\n",
    "    h1 = G.select(G.from_node).withColumn('proportion',F.lit(N))\n",
    "    h1.createOrReplaceTempView('h1')\n",
    "    h1 = spark.sql('''SELECT DISTINCT from_node, proportion\n",
    "                FROM h1''')\n",
    "\n",
    "    h2 = G.groupBy(G['from_node']).count()\n",
    "    h1.createOrReplaceTempView('h1')\n",
    "    h2.createOrReplaceTempView('h2')\n",
    "    h2 = spark.sql('''SELECT h1.from_node AS from_node1, 1/(h2.count) as proportion\n",
    "                FROM h1 JOIN h2\n",
    "                ON h1.from_node = h2.from_node''')\n",
    "\n",
    "    G.createOrReplaceTempView('G')\n",
    "    h2.createOrReplaceTempView('h2')\n",
    "    h3 = spark.sql('''SELECT DISTINCT p.from_node as from_node1, p.to_node AS node, h2.proportion AS pagerank\n",
    "                FROM G p JOIN h2\n",
    "                WHERE p.from_node = h2.from_node1\n",
    "                ORDER BY node''')\n",
    "\n",
    "    for i in range(0, num_iter):\n",
    "        h4 = h1.join(h3, h1.from_node == h3.from_node1)\n",
    "        h4 = h4.selectExpr('from_node', 'node', 'proportion', 'pagerank', 'proportion*pagerank')\n",
    "\n",
    "        h4.createOrReplaceTempView('h4')\n",
    "        h5 = spark.sql('''SELECT DISTINCT node as from_node, 0.85 * sum(proportion*pagerank) + 0.15 AS proportion\n",
    "                FROM h4\n",
    "                GROUP BY node''')\n",
    "        h1 = h5\n",
    "    return h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Step 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr_sdf.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+---------+\n",
      "|from_node|to_node|timestamp|\n",
      "+---------+-------+---------+\n",
      "|        1|      2|        0|\n",
      "|        1|      3|        0|\n",
      "|        1|      4|        0|\n",
      "|        1|      5|        0|\n",
      "|        2|      3|        0|\n",
      "|        2|      5|        0|\n",
      "|        3|      2|        0|\n",
      "|        4|      5|        0|\n",
      "|        5|      1|        0|\n",
      "|        5|      6|        0|\n",
      "|        5|      7|        0|\n",
      "|        6|      7|        0|\n",
      "|        7|      6|        0|\n",
      "|        7|      2|        0|\n",
      "|        7|      7|        0|\n",
      "|        5|      4|        0|\n",
      "+---------+-------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pr_sdf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------------+\n",
      "|from_node|         proportion|\n",
      "+---------+-------------------+\n",
      "|        4|0.36610546184882914|\n",
      "|        1| 0.3056855115440409|\n",
      "|        5| 0.8147069488207835|\n",
      "|        3| 0.5262470701160463|\n",
      "|        6| 0.5380753784802238|\n",
      "|        2|  0.843575161873236|\n",
      "|        7| 0.9433725923168398|\n",
      "+---------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pagerank(pr_sdf, 5).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
